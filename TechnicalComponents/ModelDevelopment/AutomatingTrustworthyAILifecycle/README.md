## Automating the Trustworthy AI Development Lifecycle 

When considering the future landscape of AI and how to ensure its trustworthiness, we must start to connect research and industry practices.

While the AI research community continue to innovate, adoption of AI is largely limited to Big Tech. Uptake of AI across wider industries such as healthcare, infrastructure or energy is limited. A large reason as to why businesses are not keen to adopt AI is due to a lack of trust. 

A large part of bridging the gap between research and industry is to develop AI ANYONE can trust, whether that be a GP, a CEO, a data engineer or your granddad.  

AI development platforms have been introduced to bridge the gap between research and industry. These platforms make it easy for businesses to integrate AI by abstracting away the development process. 

Unfortunately, existing platforms have been criticised for their opacity and are a long way away from being trustworthy. 

### In this repo we ask the question. How do we design an end-end platform which builds trustworthy AI, bridging the gap between research and industry? 

We develop the following technical solutions 

1. AI debunked: Translation of technical language underpinning AI into easy to understand concepts which allow the AI development cycle to be understood by anybody. 
2. Automated Model Recommendation: Encode qualitative details and requirements input into system at the “Problem Specification” stage of the pipeline in order to automate model generation and selection
3. Including Subject Matter Expert: Facilitating a dialogue between AI engineer and Subject matter Expert - both sign off on selected model 
4. Automatic Documentation Generation
